{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries:\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD, adam\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "import time \n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Below Lines should be moved to help module & imported in one line:\n",
    "def handle_data(path='output.xlsx', scale=False, include_out=False ):\n",
    "    global df\n",
    "    df=pd.read_excel(path, index=False)                                               # output of preprocessed data\n",
    "    print('Loadded data from {}'.format(path))\n",
    "    df = df.drop(['Unnamed: 0','Fillage (%)','PD (ft)','MPMPL (lb)'], axis=1)\n",
    "    if scale == False:                                                                # will normalize data                 \n",
    "        num_df=df.drop(['Fillage_low','Fillage_medium','Fillage_high','PRHP'], axis=1)      \n",
    "        num_df_norm=(num_df-num_df.mean())/(num_df.std())                              # Tensorflow tutourials \n",
    "        # num_df_norm=(num_df-num_df.mean())/(num_df.std()+1e-7)                       # Stackoverflow reply\n",
    "        cat_df_encoded=df[['Fillage_low','Fillage_medium','Fillage_high']]             # one hot coding already applied \n",
    "        label_df=df['PRHP']\n",
    "        if include_out == False:\n",
    "            df=pd.concat([num_df_norm,cat_df_encoded, label_df], axis=1)\n",
    "        else:\n",
    "            label_df=df['PRHP']/df['PRHP'].max()                                       \n",
    "            df=pd.concat([num_df_norm,cat_df_encoded, label_df], axis=1)\n",
    "        print('Normalizing Data completed')\n",
    "    else:\n",
    "        num_df=df.drop(['Fillage_low','Fillage_medium','Fillage_high','PRHP'], axis=1)\n",
    "        num_values = num_df.values                                  \n",
    "        scaler_x=MinMaxScaler(feature_range=(0,1))\n",
    "        scaler_x.fit(num_values)\n",
    "        num_values_scaled=scaler_x.transform(num_values)\n",
    "        num_df_scaled = pd.DataFrame(num_values_scaled, columns=['P.Dia (in)', 'SL (in)', 'SPM (spm)', 'B.Weight (lbf)', 'PIP (psi)',\n",
    "       'PPMPL (lb)', 'Friction (lb)'])\n",
    "        cat_df_encoded=df[['Fillage_low','Fillage_medium','Fillage_high']]             # one hot coding already applied \n",
    "        label_df=df['PRHP']\n",
    "        if include_out == False:\n",
    "            df=pd.concat([num_df_scaled,cat_df_encoded, label_df], axis=1)\n",
    "        else:\n",
    "            label_df=df['PRHP']/df['PRHP'].max()                                       \n",
    "            df=pd.concat([num_df_norm,cat_df_encoded, label_df], axis=1)\n",
    "        print('Scaling Data completed')\n",
    "    return df\n",
    "        \n",
    "# def split_data(df=df, test_size=0.15):\n",
    "#     (train_data, test_data) = train_test_split(df, test_size=test_size, random_state=42)\n",
    "#     print('Data divided as following :{} points for training and {} points for testing'.format(len(train_data), len(test_data)))\n",
    "#     train_data_features=train_data.drop('PRHP', axis=1)\n",
    "#     train_data_labels=train_data['PRHP']\n",
    "#     train_data_labels=pd.DataFrame(train_data_labels,  columns=['PRHP'])\n",
    "#     test_data_features=test_data.drop('PRHP', axis=1)\n",
    "#     test_data_labels=test_data['PRHP']\n",
    "#     print('Data separated into {} inputs and {} output'.format(train_data_features.shape[1],train_data_labels.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loadded data from output.xlsx\n",
      "Normalizing Data completed\n"
     ]
    }
   ],
   "source": [
    "# Get Data & normalize it:\n",
    "handle_data()\n",
    "df=df.iloc[0:500,]\n",
    "features=df.drop('PRHP', axis=1)\n",
    "labels=df['PRHP']\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been created\n"
     ]
    }
   ],
   "source": [
    "# Function to selectively create our model:\n",
    "def create_model(layers=[9], activation='relu', optimizer=adam, lr=1e-3):\n",
    "    model=Sequential()\n",
    "    for i, nodes in enumerate (layers):\n",
    "        if i == 0:\n",
    "            model.add(Dense(nodes,input_shape=(features.shape[1],), activation=activation))\n",
    "        else:\n",
    "            model.add(Dense(nodes,input_shape=(features.shape[1],), activation=activation))                        \n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=optimizer(lr=lr),loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "    return model\n",
    "\n",
    "model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "print('Model has been created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time : 50.54 Seconds\n",
      "Number of K-Fold cross validation: 3,  \n"
     ]
    }
   ],
   "source": [
    "# define the grid search parameters:\n",
    "# layers = [[9],[8,5]]\n",
    "# activation = ['relu', 'sigmoid','softmax','elu']\n",
    "optimizer = [adam,SGD]\n",
    "lr=[1e-3,1e-2]\n",
    "batch_size = [10, 20]\n",
    "epochs=[15,25]\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs, lr=lr, optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1,scoring='neg_mean_squared_error', cv=3 )\n",
    "start = time.time()\n",
    "grid_result = grid.fit(features, labels)\n",
    "end = time.time()\n",
    "print('Training time :', round((end-start),2), 'Seconds')\n",
    "\n",
    "# summarize results:\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "print('Number of K-Fold cross validation: {},  '.format(grid_result.n_splits_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For better accuracy use following configurations : {'batch_size': 20, 'epochs': 25, 'lr': 0.01, 'optimizer': <class 'keras.optimizers.SGD'>}\n"
     ]
    }
   ],
   "source": [
    "print('For better accuracy use following configurations : {}'.format(grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ANNMODEL] *",
   "language": "python",
   "name": "conda-env-ANNMODEL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
